# üîê Reconhecimento Facial - Guia de Integra√ß√£o

## ‚úÖ O que foi implementado

1. **‚úÖ Biblioteca face-api.js** - Downloaded em `public/face-api.min.js`
2. **‚úÖ M√≥dulo de Reconhecimento** - `public/js/face-recognition.js`
3. **‚úÖ API Backend** - 3 novos endpoints no `PwaClockController`
4. **‚úÖ Banco de Dados** - Campo `face_descriptor` na tabela `employees`
5. **‚úÖ Rotas API** - Cadastro e valida√ß√£o facial

## üìã Como Integrar no PWA (`clock.blade.php`)

### 1. Adicionar Scripts no `<head>` da p√°gina

```html
<!-- Face API -->
<script defer src="/face-api.min.js"></script>
<script defer src="/js/face-recognition.js"></script>
```

### 2. Adicionar Canvas de Detec√ß√£o (ap√≥s o v√≠deo)

Procure por `<video id="video"` e adicione logo ap√≥s:

```html
<video id="video" autoplay playsinline style="display: none;"></video>

<!-- Canvas para desenhar detec√ß√£o facial -->
<canvas id="face-canvas" style="position: absolute; top: 0; left: 0;"></canvas>

<canvas id="canvas"></canvas>
```

### 3. Adicionar Status de Reconhecimento Facial

Adicione dentro do `#video-container`:

```html
<div class="face-status" id="face-status" style="display: none;">
    <div class="face-status-icon" id="face-status-icon">üë§</div>
    <div class="face-status-text" id="face-status-text">Detectando rosto...</div>
</div>
```

E o CSS:

```css
.face-status {
    position: absolute;
    top: 20px;
    left: 20px;
    background: rgba(0, 0, 0, 0.8);
    padding: 15px 20px;
    border-radius: 10px;
    color: white;
    display: flex;
    align-items: center;
    gap: 10px;
    z-index: 20;
}

.face-status-icon {
    font-size: 24px;
}

.face-status-text {
    font-size: 14px;
    font-weight: 600;
}

.face-detected {
    background: rgba(22, 163, 74, 0.9) !important;
}

.face-not-detected {
    background: rgba(220, 38, 38, 0.9) !important;
}
```

### 4. JavaScript - Inicializar Face Recognition

Adicione no final do `<script>`, ap√≥s a fun√ß√£o `updateDateTime()`:

```javascript
// ====================
// RECONHECIMENTO FACIAL
// ====================

let faceRecognitionEnabled = false;
let employeeFaceDescriptor = null;
let faceValidated = false;

// Carrega modelos quando a p√°gina carregar
window.addEventListener('load', async () => {
    try {
        console.log('[Face] Carregando modelos...');
        const loaded = await window.faceRecognition.loadModels();
        if (loaded) {
            faceRecognitionEnabled = true;
            console.log('[Face] Reconhecimento facial ativado!');
        }
    } catch (error) {
        console.error('[Face] Erro ao carregar:', error);
        faceRecognitionEnabled = false;
    }
});

// Atualiza a fun√ß√£o startCamera() para incluir detec√ß√£o facial
async function startCamera() {
    try {
        stream = await navigator.mediaDevices.getUserMedia({
            video: {
                facingMode: 'user',
                width: { ideal: 1280 },
                height: { ideal: 720 }
            }
        });

        const video = document.getElementById('video');
        video.srcObject = stream;
        video.style.display = 'block';

        document.getElementById('camera-placeholder').style.display = 'none';
        document.getElementById('face-guide').style.display = 'block';
        document.getElementById('camera-message').style.display = 'block';

        // Aguarda v√≠deo estar pronto
        video.onloadedmetadata = () => {
            // Inicia detec√ß√£o facial se habilitado
            if (faceRecognitionEnabled && currentEmployee) {
                startFaceDetection();
            }
        };
    } catch (error) {
        console.error('Erro ao acessar c√¢mera:', error);
        playErrorSound();
        setTimeout(() => {
            resetToInitialScreen();
        }, 2000);
    }
}

// Inicia detec√ß√£o facial cont√≠nua
function startFaceDetection() {
    if (!faceRecognitionEnabled) return;

    const video = document.getElementById('video');
    const canvas = document.getElementById('face-canvas');
    const faceStatus = document.getElementById('face-status');

    faceStatus.style.display = 'flex';

    window.faceRecognition.startContinuousDetection(video, canvas, async (result) => {
        const statusIcon = document.getElementById('face-status-icon');
        const statusText = document.getElementById('face-status-text');

        if (result.detected) {
            faceStatus.classList.add('face-detected');
            faceStatus.classList.remove('face-not-detected');
            statusIcon.textContent = '‚úÖ';
            statusText.textContent = `Rosto detectado (${(result.confidence * 100).toFixed(0)}%)`;

            // Se ainda n√£o validou, valida o rosto
            if (!faceValidated && result.descriptor) {
                await validateEmployeeFace(result.descriptor);
            }
        } else {
            faceStatus.classList.remove('face-detected');
            faceStatus.classList.add('face-not-detected');
            statusIcon.textContent = '‚ùå';
            statusText.textContent = 'Nenhum rosto detectado';
            faceValidated = false;
        }
    });
}

// Para detec√ß√£o facial
function stopFaceDetection() {
    if (window.faceRecognition) {
        window.faceRecognition.stopContinuousDetection();
    }
    const faceStatus = document.getElementById('face-status');
    if (faceStatus) {
        faceStatus.style.display = 'none';
    }
}

// Valida rosto do funcion√°rio
async function validateEmployeeFace(descriptor) {
    try {
        const response = await fetch('/api/pwa/validate-face', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-CSRF-TOKEN': '{{ csrf_token() }}'
            },
            body: JSON.stringify({
                employee_id: currentEmployee.id,
                descriptor: descriptor
            })
        });

        const data = await response.json();

        if (data.match) {
            faceValidated = true;
            console.log(`[Face] ‚úÖ Validado! Similaridade: ${data.similarity}%`);

            // Atualiza status visual
            const statusText = document.getElementById('face-status-text');
            statusText.textContent = `Rosto reconhecido (${data.similarity}% match)`;

            // Som de sucesso
            playSuccessSound();
        } else if (data.needs_registration) {
            // Funcion√°rio n√£o tem rosto cadastrado - cadastra automaticamente
            console.log('[Face] Cadastrando rosto pela primeira vez...');
            await saveFaceDescriptor(descriptor);
        } else {
            console.warn(`[Face] ‚ùå Rosto n√£o reconhecido. Similaridade: ${data.similarity}%`);
            faceValidated = false;
        }
    } catch (error) {
        console.error('[Face] Erro na valida√ß√£o:', error);
    }
}

// Salva descritor facial (primeiro uso)
async function saveFaceDescriptor(descriptor) {
    try {
        const response = await fetch('/api/pwa/save-face-descriptor', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-CSRF-TOKEN': '{{ csrf_token() }}'
            },
            body: JSON.stringify({
                employee_id: currentEmployee.id,
                descriptor: descriptor
            })
        });

        const data = await response.json();

        if (data.success) {
            console.log('[Face] ‚úÖ Descritor facial cadastrado!');
            faceValidated = true;
            playSuccessSound();

            const statusText = document.getElementById('face-status-text');
            statusText.textContent = 'Rosto cadastrado com sucesso!';
        }
    } catch (error) {
        console.error('[Face] Erro ao salvar descritor:', error);
    }
}

// Atualiza fun√ß√£o captureAndRegister para incluir valida√ß√£o facial
async function captureAndRegister(action) {
    // Verifica se o rosto foi validado
    if (faceRecognitionEnabled && !faceValidated) {
        alert('‚ö†Ô∏è Aguarde a valida√ß√£o facial antes de registrar o ponto!');
        return;
    }

    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const context = canvas.getContext('2d');

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    context.save();
    context.scale(-1, 1);
    context.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
    context.restore();

    canvas.toBlob(async (blob) => {
        const formData = new FormData();
        formData.append('photo', blob, 'face.jpg');
        formData.append('employee_id', currentEmployee.id);
        formData.append('action', action);

        try {
            const response = await fetch('/api/pwa/register-clock', {
                method: 'POST',
                headers: {
                    'X-CSRF-TOKEN': '{{ csrf_token() }}'
                },
                body: formData
            });

            const data = await response.json();

            if (data.success) {
                playCameraShutterSound();
                setTimeout(() => {
                    resetToInitialScreen();
                }, 1000);
            } else {
                playErrorSound();
                alert(data.message || 'Erro ao registrar ponto');
            }
        } catch (error) {
            console.error('Erro ao registrar:', error);
            playErrorSound();
        }
    }, 'image/jpeg', 0.9);
}

// Atualiza resetToInitialScreen para parar detec√ß√£o
function resetToInitialScreen() {
    // Para detec√ß√£o facial
    stopFaceDetection();

    // Para a c√¢mera
    if (stream) {
        stream.getTracks().forEach(track => track.stop());
        stream = null;
    }

    // Reseta vari√°veis
    currentEmployee = null;
    currentCode = '';
    faceValidated = false;

    // Esconde v√≠deo e mostra placeholder
    document.getElementById('video').style.display = 'none';
    document.getElementById('camera-placeholder').style.display = 'flex';
    document.getElementById('face-guide').style.display = 'none';
    document.getElementById('camera-message').style.display = 'none';

    // Esconde painel de a√ß√µes e mostra teclado
    document.getElementById('action-panel').style.display = 'none';
    document.getElementById('numpad-container').style.display = 'flex';

    // Limpa display
    updateDisplay();
}
```

## üöÄ Como Testar

1. **Acesse o PWA**: `http://localhost:8000/pwa/clock`
2. **Digite o c√≥digo do funcion√°rio**: Ex: 936923
3. **Aguarde a detec√ß√£o facial**: Box verde aparecer√° ao redor do rosto
4. **Primeiro uso**: Rosto ser√° cadastrado automaticamente
5. **Pr√≥ximos usos**: Sistema validar√° se √© o mesmo rosto
6. **Registre o ponto**: Clique em "Registrar Entrada"

## üìä Endpoints API Criados

| M√©todo | Endpoint | Descri√ß√£o |
|--------|----------|-----------|
| POST | `/api/pwa/save-face-descriptor` | Cadastra descritor facial do funcion√°rio |
| POST | `/api/pwa/validate-face` | Valida se o rosto detectado corresponde ao funcion√°rio |

## üîí Seguran√ßa Implementada

1. **Liveness Detection**: Detecta express√µes faciais
2. **Threshold 0.6**: Similaridade m√≠nima de 60%
3. **Confian√ßa M√≠nima**: 50% de confian√ßa na detec√ß√£o
4. **Descritor 128D**: "Impress√£o digital" facial √∫nica

## üéØ Pr√≥ximas Melhorias

- [ ] Liveness Detection avan√ßado (piscar olhos)
- [ ] M√∫ltiplos rostos cadastrados
- [ ] Hist√≥rico de tentativas de fraude
- [ ] Dashboard de reconhecimentos
- [ ] Alertas de tentativa de acesso n√£o autorizado
